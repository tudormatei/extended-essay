{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization, MaxPool2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from subprocess import check_output\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base input image data\n",
    "\n",
    "img_height = 30\n",
    "img_width = 30\n",
    "channels = 3\n",
    "image_shape = (img_height, img_width, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.29411766, 0.30588236, 0.3137255 ],\n",
       "        [0.2901961 , 0.29803923, 0.30588236],\n",
       "        [0.3372549 , 0.34117648, 0.32941177],\n",
       "        ...,\n",
       "        [0.26666668, 0.29411766, 0.29411766],\n",
       "        [0.25490198, 0.27058825, 0.26666668],\n",
       "        [0.25882354, 0.2627451 , 0.25882354]],\n",
       "\n",
       "       [[0.3254902 , 0.32941177, 0.3372549 ],\n",
       "        [0.3137255 , 0.3137255 , 0.32156864],\n",
       "        [0.3529412 , 0.34901962, 0.32941177],\n",
       "        ...,\n",
       "        [0.28627452, 0.3019608 , 0.30588236],\n",
       "        [0.29803923, 0.30588236, 0.29411766],\n",
       "        [0.3137255 , 0.3137255 , 0.30588236]],\n",
       "\n",
       "       [[0.30588236, 0.30588236, 0.3137255 ],\n",
       "        [0.3372549 , 0.33333334, 0.3372549 ],\n",
       "        [0.3647059 , 0.3529412 , 0.35686275],\n",
       "        ...,\n",
       "        [0.28235295, 0.2901961 , 0.28235295],\n",
       "        [0.28627452, 0.2901961 , 0.27058825],\n",
       "        [0.30588236, 0.30588236, 0.2901961 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.52156866, 0.5254902 , 0.54509807],\n",
       "        [0.47843137, 0.49803922, 0.5176471 ],\n",
       "        [0.4392157 , 0.4745098 , 0.4862745 ],\n",
       "        ...,\n",
       "        [0.36862746, 0.36862746, 0.34901962],\n",
       "        [0.38039216, 0.38431373, 0.35686275],\n",
       "        [0.3882353 , 0.40392157, 0.3882353 ]],\n",
       "\n",
       "       [[0.35686275, 0.37254903, 0.3882353 ],\n",
       "        [0.35686275, 0.38431373, 0.40392157],\n",
       "        [0.2901961 , 0.33333334, 0.34901962],\n",
       "        ...,\n",
       "        [0.40392157, 0.39607844, 0.37254903],\n",
       "        [0.43137255, 0.44313726, 0.40784314],\n",
       "        [0.3764706 , 0.40784314, 0.38431373]],\n",
       "\n",
       "       [[0.33333334, 0.32941177, 0.34117648],\n",
       "        [0.37254903, 0.39607844, 0.41960785],\n",
       "        [0.23921569, 0.2901961 , 0.30980393],\n",
       "        ...,\n",
       "        [0.4       , 0.4       , 0.37254903],\n",
       "        [0.3882353 , 0.4       , 0.3529412 ],\n",
       "        [0.3529412 , 0.38039216, 0.34901962]]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verifing that the training images are already normalized (values between 0 and 1)\n",
    "\n",
    "imread('.//data//train//0//00000_00000_00000.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the image generator from the training folder\n",
    "\n",
    "train_path = './/data//train'\n",
    "\n",
    "image_gen = ImageDataGenerator(shear_range=0.1, # Shear means cutting away part of the image (max 10%)\n",
    "                               zoom_range=0.1, # Zoom in by 10% max\n",
    "                               horizontal_flip=False, # Allo horizontal flipping\n",
    "                               fill_mode='nearest', # Fill in missing pixels with the nearest filled value\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=(3,3), activation='relu', input_shape=image_shape))\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu', input_shape=image_shape))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(43, activation='sigmoid'))  \n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 16)        448       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 13, 13, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 43)                22059     \n",
      "=================================================================\n",
      "Total params: 1,171,275\n",
      "Trainable params: 1,169,931\n",
      "Non-trainable params: 1,344\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 39209 images belonging to 43 classes.\n"
     ]
    }
   ],
   "source": [
    "#Creating the training and validation generator (validation is both testing and validation)\n",
    "\n",
    "train_generator = image_gen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=image_shape[:2],\n",
    "    batch_size=batch_size,\n",
    "    color_mode='rgb',\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\tensorflowGPU\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2451/2451 [==============================] - 72s 29ms/step - loss: 0.9655 - accuracy: 0.7590\n",
      "Epoch 2/20\n",
      "2451/2451 [==============================] - 67s 27ms/step - loss: 0.1081 - accuracy: 0.9669\n",
      "Epoch 3/20\n",
      "2451/2451 [==============================] - 72s 29ms/step - loss: 0.0814 - accuracy: 0.9753\n",
      "Epoch 4/20\n",
      "2451/2451 [==============================] - 70s 29ms/step - loss: 0.0643 - accuracy: 0.9806\n",
      "Epoch 5/20\n",
      "2451/2451 [==============================] - 68s 28ms/step - loss: 0.0815 - accuracy: 0.9750\n",
      "Epoch 6/20\n",
      "2451/2451 [==============================] - 69s 28ms/step - loss: 0.0375 - accuracy: 0.9884\n",
      "Epoch 7/20\n",
      "2451/2451 [==============================] - 72s 29ms/step - loss: 0.0382 - accuracy: 0.9883\n",
      "Epoch 8/20\n",
      "2451/2451 [==============================] - 70s 29ms/step - loss: 0.0325 - accuracy: 0.9900\n",
      "Epoch 9/20\n",
      "2451/2451 [==============================] - 70s 28ms/step - loss: 0.0300 - accuracy: 0.9911\n",
      "Epoch 10/20\n",
      "2451/2451 [==============================] - 70s 28ms/step - loss: 0.0271 - accuracy: 0.9915\n",
      "Epoch 11/20\n",
      "2451/2451 [==============================] - 70s 29ms/step - loss: 0.0238 - accuracy: 0.9928\n",
      "Epoch 12/20\n",
      "2451/2451 [==============================] - 70s 29ms/step - loss: 0.0284 - accuracy: 0.9919\n",
      "Epoch 13/20\n",
      "2451/2451 [==============================] - 70s 29ms/step - loss: 0.0222 - accuracy: 0.9940\n",
      "Epoch 14/20\n",
      "2451/2451 [==============================] - 70s 29ms/step - loss: 0.0208 - accuracy: 0.9938\n",
      "Epoch 15/20\n",
      "2451/2451 [==============================] - 70s 29ms/step - loss: 0.0172 - accuracy: 0.9953\n",
      "Epoch 16/20\n",
      "2451/2451 [==============================] - 70s 29ms/step - loss: 0.0167 - accuracy: 0.9950\n",
      "Epoch 17/20\n",
      "2451/2451 [==============================] - 69s 28ms/step - loss: 0.0245 - accuracy: 0.9937\n",
      "Epoch 18/20\n",
      "2451/2451 [==============================] - 68s 28ms/step - loss: 0.0185 - accuracy: 0.9951\n",
      "Epoch 19/20\n",
      "2451/2451 [==============================] - 69s 28ms/step - loss: 0.0173 - accuracy: 0.9951\n",
      "Epoch 20/20\n",
      "2451/2451 [==============================] - 68s 28ms/step - loss: 0.0147 - accuracy: 0.9956\n"
     ]
    }
   ],
   "source": [
    "#Training the model\n",
    "\n",
    "results = model.fit_generator(train_generator,epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model\n",
    "\n",
    "model.save('traffic_sign_classifier2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(train_generator, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Test accuracy : 0.9998'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Test accuracy : {:.4f}'.format(score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving history of the model as a dictionary\n",
    "\n",
    "history_dict = results.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'val_loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3600/802312356.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mloss_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mval_loss_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_values\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'val_loss'"
     ]
    }
   ],
   "source": [
    "#Plotting loss and validation loss against epochs\n",
    "\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "\n",
    "line1 = plt.plot(epochs, val_loss_values, label = \"Validation/Test Loss\")\n",
    "line2 = plt.plot(epochs, loss_values, label = \"Training Loss\")\n",
    "plt.setp(line1, linewidth=2.0, marker= '+', markersize = 10)\n",
    "plt.setp(line2, linewidth=2.0, marker= '4', markersize = 10)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'val_accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3600/3543134792.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0macc_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mval_acc_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_values\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'val_accuracy'"
     ]
    }
   ],
   "source": [
    "#Plotting acc and validation acc against epochs\n",
    "\n",
    "acc_values = history_dict['accuracy']\n",
    "val_acc_values = history_dict['val_accuracy']\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "\n",
    "line1 = plt.plot(epochs, val_acc_values, label = \"Validation/Test Accuracy\")\n",
    "line2 = plt.plot(epochs, acc_values, label = \"Training Accuracy\")\n",
    "plt.setp(line1, linewidth=2.0, marker= '+', markersize = 10)\n",
    "plt.setp(line2, linewidth=2.0, marker= '4', markersize = 10)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classes dictionary\n",
    "\n",
    "classes = { 0:'Speed limit (20km/h)',\n",
    "            1:'Speed limit (30km/h)', \n",
    "            2:'Speed limit (50km/h)', \n",
    "            3:'Speed limit (60km/h)', \n",
    "            4:'Speed limit (70km/h)', \n",
    "            5:'Speed limit (80km/h)', \n",
    "            6:'End of speed limit (80km/h)', \n",
    "            7:'Speed limit (100km/h)', \n",
    "            8:'Speed limit (120km/h)', \n",
    "            9:'No passing', \n",
    "            10:'No passing veh over 3.5 tons', \n",
    "            11:'Right-of-way at intersection', \n",
    "            12:'Priority road', \n",
    "            13:'Yield', \n",
    "            14:'Stop', \n",
    "            15:'No vehicles', \n",
    "            16:'Veh > 3.5 tons prohibited', \n",
    "            17:'No entry', \n",
    "            18:'General caution', \n",
    "            19:'Dangerous curve left', \n",
    "            20:'Dangerous curve right', \n",
    "            21:'Double curve', \n",
    "            22:'Bumpy road', \n",
    "            23:'Slippery road', \n",
    "            24:'Road narrows on the right', \n",
    "            25:'Road work', \n",
    "            26:'Traffic signals', \n",
    "            27:'Pedestrians', \n",
    "            28:'Children crossing', \n",
    "            29:'Bicycles crossing', \n",
    "            30:'Beware of ice/snow',\n",
    "            31:'Wild animals crossing', \n",
    "            32:'End speed + passing limits', \n",
    "            33:'Turn right ahead', \n",
    "            34:'Turn left ahead', \n",
    "            35:'Ahead only', \n",
    "            36:'Go straight or right', \n",
    "            37:'Go straight or left', \n",
    "            38:'Keep right', \n",
    "            39:'Keep left', \n",
    "            40:'Roundabout mandatory', \n",
    "            41:'End of no passing', \n",
    "            42:'End no passing veh > 3.5 tons' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 30, 30, 3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inputting the image to be predicted\n",
    "\n",
    "img_path = './/data//train//1//00001_00002_00024.png'\n",
    "\n",
    "my_image = image.load_img(img_path, target_size=image_shape)\n",
    "my_image = image.img_to_array(my_image)\n",
    "\n",
    "my_image = my_image / 255 # Transforming into array and normalizing it\n",
    "my_image = np.expand_dims(my_image, axis=0) #Expanding from (30, 30, 3) to (1, 30, 30, 3)\n",
    "\n",
    "my_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the model\n",
    "\n",
    "model = load_model('traffic_sign_classifier2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'my_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10644/2802699994.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'my_image' is not defined"
     ]
    }
   ],
   "source": [
    "model.predict_classes(my_image)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib.image import imread\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data accuracy:  5.479018210609659\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('.//data//' + 'Test.csv')\n",
    "\n",
    "labels = test[\"ClassId\"].values\n",
    "imgs = test[\"Path\"].values\n",
    "\n",
    "data = []\n",
    "\n",
    "for img in imgs:\n",
    "    try:\n",
    "        image = cv2.imread('.//data//' + img)\n",
    "        image_fromarray = Image.fromarray(image, 'RGB')\n",
    "        resize_image = image_fromarray.resize((30, 30))\n",
    "        data.append(np.array(resize_image))\n",
    "    except:\n",
    "        print(\"Error in \" + img)\n",
    "X_test = np.array(data)\n",
    "X_test = X_test/255\n",
    "\n",
    "pred = model.predict_classes(X_test)\n",
    "\n",
    "#Accuracy with the test data\n",
    "print('Test Data accuracy: ',accuracy_score(labels, pred)*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
